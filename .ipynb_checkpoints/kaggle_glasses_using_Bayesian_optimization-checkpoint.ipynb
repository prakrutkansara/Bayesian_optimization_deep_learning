{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify if the Gan-faces is wearing glasses or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to determine if a person is wearing glasses or not using data contianing all features. These features are generated from a Generative Adversarial Neural Network (GAN). The detailed information can refer to [here](https://www.kaggle.com/jeffheaton/glasses-or-no-glasses).\n",
    "### Data\n",
    "There are two data were used for this project: **(1)** training.csv, which include the 512 features one response variable glasses (1 represent have glass, 0 means no glasses). **(2)** submit.csv, which in fact is the test data which to measure how good of the model.\n",
    "\n",
    "**Objetive**: To classify the data into two category use optmized netrual network with Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "import tensorflow.keras\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from scipy.stats import norm,kstest\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if import kstest or shaprio give me problem, maybe try to downgrade your scipy\n",
    "#!pip3 install --user scipy==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train data\n",
    "df_train = pd.read_csv(\"./data/train.csv\",\n",
    "                       na_values=['NA','?'])\n",
    "df_train.drop('id',axis =1, inplace = True)\n",
    "\n",
    "## submit data\n",
    "df_submit = pd.read_csv(\"./data/test.csv\",\n",
    "                       na_values=['NA','?'])\n",
    "ids = df_submit['id']\n",
    "df_submit.drop('id',axis =1, inplace = True)\n",
    "x_submit = df_submit.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v504</th>\n",
       "      <th>v505</th>\n",
       "      <th>v506</th>\n",
       "      <th>v507</th>\n",
       "      <th>v508</th>\n",
       "      <th>v509</th>\n",
       "      <th>v510</th>\n",
       "      <th>v511</th>\n",
       "      <th>v512</th>\n",
       "      <th>glasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029433</td>\n",
       "      <td>-0.072952</td>\n",
       "      <td>-0.063137</td>\n",
       "      <td>-0.027426</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>-0.032587</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>-0.101231</td>\n",
       "      <td>-0.134099</td>\n",
       "      <td>0.067560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>0.057622</td>\n",
       "      <td>-0.063235</td>\n",
       "      <td>-0.081697</td>\n",
       "      <td>-0.032337</td>\n",
       "      <td>-0.084307</td>\n",
       "      <td>-0.032826</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>-0.064696</td>\n",
       "      <td>0.634667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.769812</td>\n",
       "      <td>0.740963</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.744712</td>\n",
       "      <td>0.775853</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.761690</td>\n",
       "      <td>0.748796</td>\n",
       "      <td>0.746005</td>\n",
       "      <td>0.747827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735644</td>\n",
       "      <td>0.739561</td>\n",
       "      <td>0.731691</td>\n",
       "      <td>0.761166</td>\n",
       "      <td>0.738119</td>\n",
       "      <td>0.743303</td>\n",
       "      <td>0.756891</td>\n",
       "      <td>0.737970</td>\n",
       "      <td>0.830538</td>\n",
       "      <td>0.481577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.895330</td>\n",
       "      <td>-2.381940</td>\n",
       "      <td>-2.599930</td>\n",
       "      <td>-2.748930</td>\n",
       "      <td>-2.291530</td>\n",
       "      <td>-4.020940</td>\n",
       "      <td>-2.736720</td>\n",
       "      <td>-2.872970</td>\n",
       "      <td>-2.397950</td>\n",
       "      <td>-2.768610</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.788230</td>\n",
       "      <td>-2.624400</td>\n",
       "      <td>-2.806240</td>\n",
       "      <td>-2.907480</td>\n",
       "      <td>-3.136690</td>\n",
       "      <td>-2.490630</td>\n",
       "      <td>-2.510730</td>\n",
       "      <td>-2.626380</td>\n",
       "      <td>-2.906970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.489807</td>\n",
       "      <td>-0.568788</td>\n",
       "      <td>-0.575425</td>\n",
       "      <td>-0.548003</td>\n",
       "      <td>-0.541330</td>\n",
       "      <td>-0.550515</td>\n",
       "      <td>-0.516868</td>\n",
       "      <td>-0.582322</td>\n",
       "      <td>-0.658523</td>\n",
       "      <td>-0.455873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537458</td>\n",
       "      <td>-0.445472</td>\n",
       "      <td>-0.546610</td>\n",
       "      <td>-0.601095</td>\n",
       "      <td>-0.506628</td>\n",
       "      <td>-0.605840</td>\n",
       "      <td>-0.546325</td>\n",
       "      <td>-0.373465</td>\n",
       "      <td>-0.615955</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.001540</td>\n",
       "      <td>-0.097665</td>\n",
       "      <td>-0.053115</td>\n",
       "      <td>-0.058240</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>-0.046450</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>-0.097295</td>\n",
       "      <td>-0.149740</td>\n",
       "      <td>0.065725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124335</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>-0.045235</td>\n",
       "      <td>-0.103520</td>\n",
       "      <td>-0.038690</td>\n",
       "      <td>-0.099355</td>\n",
       "      <td>-0.032260</td>\n",
       "      <td>0.113235</td>\n",
       "      <td>-0.082685</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.507332</td>\n",
       "      <td>0.405330</td>\n",
       "      <td>0.458388</td>\n",
       "      <td>0.478182</td>\n",
       "      <td>0.555465</td>\n",
       "      <td>0.498605</td>\n",
       "      <td>0.506625</td>\n",
       "      <td>0.379340</td>\n",
       "      <td>0.377330</td>\n",
       "      <td>0.584847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370607</td>\n",
       "      <td>0.571075</td>\n",
       "      <td>0.438712</td>\n",
       "      <td>0.429145</td>\n",
       "      <td>0.459985</td>\n",
       "      <td>0.417492</td>\n",
       "      <td>0.495537</td>\n",
       "      <td>0.585468</td>\n",
       "      <td>0.469020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.518200</td>\n",
       "      <td>2.452530</td>\n",
       "      <td>3.637160</td>\n",
       "      <td>2.775740</td>\n",
       "      <td>3.247220</td>\n",
       "      <td>3.028140</td>\n",
       "      <td>2.761340</td>\n",
       "      <td>2.548660</td>\n",
       "      <td>2.384070</td>\n",
       "      <td>2.540040</td>\n",
       "      <td>...</td>\n",
       "      <td>2.954360</td>\n",
       "      <td>2.375880</td>\n",
       "      <td>2.641460</td>\n",
       "      <td>3.227290</td>\n",
       "      <td>2.654210</td>\n",
       "      <td>2.833950</td>\n",
       "      <td>2.632360</td>\n",
       "      <td>2.405620</td>\n",
       "      <td>2.827810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "count  4500.000000  4500.000000  4500.000000  4500.000000  4500.000000   \n",
       "mean      0.029433    -0.072952    -0.063137    -0.027426     0.009050   \n",
       "std       0.769812     0.740963     0.746607     0.744712     0.775853   \n",
       "min      -2.895330    -2.381940    -2.599930    -2.748930    -2.291530   \n",
       "25%      -0.489807    -0.568788    -0.575425    -0.548003    -0.541330   \n",
       "50%      -0.001540    -0.097665    -0.053115    -0.058240     0.003175   \n",
       "75%       0.507332     0.405330     0.458388     0.478182     0.555465   \n",
       "max       2.518200     2.452530     3.637160     2.775740     3.247220   \n",
       "\n",
       "                v6           v7           v8           v9          v10  ...  \\\n",
       "count  4500.000000  4500.000000  4500.000000  4500.000000  4500.000000  ...   \n",
       "mean     -0.032587     0.005451    -0.101231    -0.134099     0.067560  ...   \n",
       "std       0.770992     0.761690     0.748796     0.746005     0.747827  ...   \n",
       "min      -4.020940    -2.736720    -2.872970    -2.397950    -2.768610  ...   \n",
       "25%      -0.550515    -0.516868    -0.582322    -0.658523    -0.455873  ...   \n",
       "50%      -0.046450     0.005075    -0.097295    -0.149740     0.065725  ...   \n",
       "75%       0.498605     0.506625     0.379340     0.377330     0.584847  ...   \n",
       "max       3.028140     2.761340     2.548660     2.384070     2.540040  ...   \n",
       "\n",
       "              v504         v505         v506         v507         v508  \\\n",
       "count  4500.000000  4500.000000  4500.000000  4500.000000  4500.000000   \n",
       "mean     -0.091886     0.057622    -0.063235    -0.081697    -0.032337   \n",
       "std       0.735644     0.739561     0.731691     0.761166     0.738119   \n",
       "min      -2.788230    -2.624400    -2.806240    -2.907480    -3.136690   \n",
       "25%      -0.537458    -0.445472    -0.546610    -0.601095    -0.506628   \n",
       "50%      -0.124335     0.034310    -0.045235    -0.103520    -0.038690   \n",
       "75%       0.370607     0.571075     0.438712     0.429145     0.459985   \n",
       "max       2.954360     2.375880     2.641460     3.227290     2.654210   \n",
       "\n",
       "              v509         v510         v511         v512      glasses  \n",
       "count  4500.000000  4500.000000  4500.000000  4500.000000  4500.000000  \n",
       "mean     -0.084307    -0.032826     0.096038    -0.064696     0.634667  \n",
       "std       0.743303     0.756891     0.737970     0.830538     0.481577  \n",
       "min      -2.490630    -2.510730    -2.626380    -2.906970     0.000000  \n",
       "25%      -0.605840    -0.546325    -0.373465    -0.615955     0.000000  \n",
       "50%      -0.099355    -0.032260     0.113235    -0.082685     1.000000  \n",
       "75%       0.417492     0.495537     0.585468     0.469020     1.000000  \n",
       "max       2.833950     2.632360     2.405620     2.827810     1.000000  \n",
       "\n",
       "[8 rows x 513 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train.isnull().sum()>0)\n",
    "##if is zero means no missing vales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_Name</th>\n",
       "      <th>Num_Unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>glasses</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>v463</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>v310</td>\n",
       "      <td>4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>v372</td>\n",
       "      <td>4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>v448</td>\n",
       "      <td>4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>v419</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>v82</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>v257</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>v464</td>\n",
       "      <td>4472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>v75</td>\n",
       "      <td>4476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column_Name  Num_Unique\n",
       "512     glasses           2\n",
       "462        v463        4434\n",
       "309        v310        4436\n",
       "371        v372        4439\n",
       "447        v448        4440\n",
       "..          ...         ...\n",
       "418        v419        4471\n",
       "81          v82        4471\n",
       "256        v257        4471\n",
       "463        v464        4472\n",
       "74          v75        4476\n",
       "\n",
       "[513 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = list(df_train.columns)\n",
    "\n",
    "unique_counts = pd.DataFrame.from_records([(col, df_train[col].nunique()) for col in df_train.columns],\n",
    "                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\n",
    "\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we can see all of predictors are numeric, only response is binary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distribution using Shapiro Wilk test\n",
    "\n",
    "If the P-Value of the Shapiro Wilk Test is larger than 0.05, we assume a normal distribution\n",
    "If the P-Value of the Shapiro Wilk Test is smaller than 0.05, we do not assume a normal distribution\n",
    "\n",
    "More detailed information on normal distribution can be found \n",
    "https://towardsdatascience.com/6-ways-to-test-for-a-normal-distribution-which-one-to-use-9dcf47d8fa93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_distribution(df, cols):\n",
    "    ks_results = []\n",
    "    \n",
    "    for col in cols:\n",
    "        #ks_statistic, p_value = kstest(df[col],'norm')\n",
    "        sw_statistic, p_value = stats.shapiro(df_train['v1'])\n",
    "        re = [col,sw_statistic, p_value]\n",
    "        ks_results.append(re)\n",
    "        \n",
    "    return ks_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(df_train.columns.values)\n",
    "predictors.remove('glasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test = pd.DataFrame(check_normal_distribution(df_train, cols = predictors),\n",
    "                           columns=['features','sw_stat','p_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>sw_stat</th>\n",
       "      <th>p_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [features, sw_stat, p_values]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_test[normal_test['p_values']>=0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000012990EF7C88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991AB8C48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991DC2D08>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000012991DF9E48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991E31F48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991E69FC8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000012991EA8148>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991EDE288>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000012991EE4E48>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[predictors[1:10]].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the SW test, all predictors are not normally distributed. But when I plot some of them, it look like they are normally distributed. Thus, let's first **not conduct normalization** for these predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building \n",
    "\n",
    "NN is what we want to use, but we don't how many layers should be included, the number of neurons and dropout will best for our analysis. Thus, the generate_model is mainly for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_model(dropout, neuronPct, neuronShrink,num_class,init_num_neurons = 4000):\n",
    "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
    "    neuronCount = int(neuronPct * init_num_neurons)\n",
    "    \n",
    "    # Construct neural network\n",
    "    # kernel_initializer = tensorflow.keras.initializers.he_uniform(seed=None)\n",
    "    model = Sequential()\n",
    "\n",
    "    # So long as there would have been at least 25 neurons and fewer than 10\n",
    "    # layers, create a new layer.\n",
    "    layer = 0\n",
    "    while neuronCount>25 and layer<10:\n",
    "        # The first (0th) layer needs an input input_dim(neuronCount)\n",
    "        if layer==0:\n",
    "            model.add(Dense(neuronCount, \n",
    "                input_dim=x.shape[1], \n",
    "                activation=PReLU()))\n",
    "        else:\n",
    "            model.add(Dense(neuronCount, activation=PReLU())) \n",
    "        layer += 1\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # Add dropout after each hidden layer\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        # Shrink neuron count for each layer\n",
    "        neuronCount = neuronCount * neuronShrink\n",
    "    if num_class>2:\n",
    "         model.add(Dense(num_class,activation='softmax')) \n",
    "    else:\n",
    "        model.add(Dense(num_class,activation='sigmoid')) # Output\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step for Bayesian optimization is to define the optimized function. The following code is to define the loss for the model we define above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network(dropout,lr,neuronPct,neuronShrink,num_class,training = True):\n",
    "    SPLITS = 5\n",
    "\n",
    "    # Bootstrap\n",
    "    boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.2)\n",
    "\n",
    "    # Track progress\n",
    "    mean_benchmark = []\n",
    "    epochs_needed = []\n",
    "    num = 0\n",
    "    \n",
    "    sub_result = np.zeros((x_submit.shape[0],SPLITS))\n",
    "    # Loop through samples\n",
    "    for train, test in boot.split(x,y):\n",
    "        start_time = time.time()\n",
    "        num+=1\n",
    "\n",
    "        # Split train and test\n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "\n",
    "        model = generate_model(dropout, neuronPct, neuronShrink,num_class)\n",
    "        if num_class>2:\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr))\n",
    "        else:\n",
    "            model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr))\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "        # Train on the bootstrap sample\n",
    "        model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "        epochs = monitor.stopped_epoch\n",
    "        epochs_needed.append(epochs)\n",
    "\n",
    "        # Predict on the out of boot (validation)\n",
    "        pred = model.predict(x_test)\n",
    "\n",
    "        ## Predict on the submit data\n",
    "        pred2 = model.predict(x_submit)[:,1]\n",
    "        sub_result[:,(num - 1)] = pred2\n",
    "        \n",
    "        # Measure this bootstrap's log loss\n",
    "        y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
    "        score = metrics.log_loss(y_compare, pred)\n",
    "        mean_benchmark.append(score)\n",
    "        m1 = statistics.mean(mean_benchmark)\n",
    "        m2 = statistics.mean(epochs_needed)\n",
    "        mdev = statistics.pstdev(mean_benchmark)\n",
    "\n",
    "        # Record this iteration\n",
    "        time_took = time.time() - start_time\n",
    "        #print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)}, time={hms_string(time_took)}\")\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    sub_mean = sub_result.mean(1)\n",
    "    if training:\n",
    "        return (-m1)\n",
    "    else:\n",
    "        return sub_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df_train.columns) # x+y column names\n",
    "names.remove(\"glasses\")\n",
    "num_class = df_train['glasses'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train[names].values\n",
    "dummies = pd.get_dummies(df_train['glasses']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a simple test\n",
    "re = evaluate_network(\n",
    "    dropout=0.2,\n",
    "    lr=1e-3,\n",
    "    neuronPct=0.1,\n",
    "    neuronShrink=0.3,\n",
    "    num_class = 2,\n",
    "    training = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization\n",
    "* [bayesian-optimization](https://github.com/fmfn/BayesianOptimization)\n",
    "\n",
    "Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  dropout  |    lr     | neuronPct | neuron... | num_class |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.01763 \u001b[0m | \u001b[0m 0.2081  \u001b[0m | \u001b[0m 0.07203 \u001b[0m | \u001b[0m 0.01011 \u001b[0m | \u001b[0m 0.3093  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.000452\u001b[0m | \u001b[95m 0.04608 \u001b[0m | \u001b[95m 0.01863 \u001b[0m | \u001b[95m 0.3521  \u001b[0m | \u001b[95m 0.4028  \u001b[0m | \u001b[95m 2.0     \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.000386\u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 0.06852 \u001b[0m | \u001b[95m 0.2124  \u001b[0m | \u001b[95m 0.8793  \u001b[0m | \u001b[95m 2.0     \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.000461\u001b[0m | \u001b[0m 0.3346  \u001b[0m | \u001b[0m 0.04173 \u001b[0m | \u001b[0m 0.5631  \u001b[0m | \u001b[0m 0.149   \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.000206\u001b[0m | \u001b[95m 0.3996  \u001b[0m | \u001b[95m 0.09683 \u001b[0m | \u001b[95m 0.3203  \u001b[0m | \u001b[95m 0.6954  \u001b[0m | \u001b[95m 2.0     \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.002711\u001b[0m | \u001b[0m 0.4464  \u001b[0m | \u001b[0m 0.008504\u001b[0m | \u001b[0m 0.04866 \u001b[0m | \u001b[0m 0.1781  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.000611\u001b[0m | \u001b[0m 0.04908 \u001b[0m | \u001b[0m 0.04211 \u001b[0m | \u001b[0m 0.9583  \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.000342\u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 0.06865 \u001b[0m | \u001b[0m 0.8363  \u001b[0m | \u001b[0m 0.02811 \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.000458\u001b[0m | \u001b[0m 0.4934  \u001b[0m | \u001b[0m 0.07482 \u001b[0m | \u001b[0m 0.2876  \u001b[0m | \u001b[0m 0.7914  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.000676\u001b[0m | \u001b[0m 0.2235  \u001b[0m | \u001b[0m 0.09086 \u001b[0m | \u001b[0m 0.3007  \u001b[0m | \u001b[0m 0.2949  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.010673356515966627, 0.08324792105112068, 0.9397545597373019, 0.985959642159091, 2.0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-63a8e140b0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mtime_took\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-94034ed879e9>\u001b[0m in \u001b[0;36mevaluate_network\u001b[1;34m(dropout, lr, neuronPct, neuronShrink, num_class, training)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Train on the bootstrap sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mepochs_needed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import time\n",
    "\n",
    "# Supress NaN warnings, see: https://stackoverflow.com/questions/34955158/what-might-be-the-cause-of-invalid-value-encountered-in-less-equal-in-numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category =RuntimeWarning)\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'dropout': (0.0, 0.499),\n",
    "           'lr': (0.0, 0.1),\n",
    "           'neuronPct': (0.01, 1),\n",
    "           'neuronShrink': (0.01, 1),\n",
    "           'num_class':(2,2)\n",
    "          }\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=evaluate_network,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer.maximize(init_points=10, n_iter=100,)\n",
    "time_took = time.time() - start_time\n",
    "\n",
    "print(f\"Total runtime: {hms_string(time_took)}\")\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.3995715397690928,\n",
       " 'lr': 0.09682615757193976,\n",
       " 'neuronPct': 0.3202899363776504,\n",
       " 'neuronShrink': 0.6953993895126209,\n",
       " 'num_class': 2.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_re = evaluate_network(\n",
    "    dropout=optimizer.max['params']['dropout'],\n",
    "    lr=optimizer.max['params']['lr'],\n",
    "    neuronPct=optimizer.max['params']['neuronPct'],\n",
    "    neuronShrink=optimizer.max['params']['neuronShrink'],\n",
    "    num_class = optimizer.max['params']['num_class'],\n",
    "    training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_re.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
